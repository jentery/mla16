# Computer Vision as a Public Act: On Digital Humanities and Algocracy 

*These are my opening remarks for the "Disrupting the Digital Humanities" session at MLA 2016.* 

For the next three minutes, I would like to speak briefly about the relevance of "algocracy," or what A. Aneesh describes as "rule of the algorithm" or "rule of the code" (Aneesh 2006: 5), to the practice of digital humanities (DH). In the context of DH, we might understand algocracy as the delegation of labor and decisions to algorithms; the everyday role algorithms play in claims about history, culture, and aesthetics; or how difference and ambiguity are treated as technical problems with design solutions, not as cultural and social issues fundamental to interpretation. Alcocracy is intricately intertwined with something called "computer vision," or the programmatic description and reconstruction of the physical world in digital form (Szeliski 2010: 3-10). Computer vision applications include optical character recognition and face recognition, which are frequently integrated into artificial intelligence systems for the purposes of prediction and modeling.  

Rather than detailing how algocracy operates within and beyond DH, today I want to list ways we might intervene in it: 

* First, we need to historicize the technologies we use. For instance, since the 1960s, computer vision research (or vision science) has not only parsed human from computer perception but also universalized them both.  
* Second, we should highlight the fact that the technologies we use, and how we use them, correspond with who is represented by DH and how. Matters of representation and value shape what we build and use. 
* Third, for social and cultural critiques of technologies, the technical and material particulars of algorithms are indeed significant. However, knowing them will not "solve" injustices or create just conditions. Put differently, knowing how to program, or knowing how to build or make a digital project, is not synonymous with understanding how technologies are social relations entangled with the production of meaning and power. 
* Fourth, we might consider how the act of programming (like writing) never involves total knowledge of what is being processed. For instance, with face recognition, computer vision scripts frequently call existing code and trusted cascades. That is, they do not produce the datasets they then use to interpret faces. 
* Fifth, when working with algorithms, we might avoid logics of individual control as well as logics of romantic play. The former invest too much in the power of programming, while the latter usually ignores social consequences or fetishizes aesthetics. 
* Finally, we should consider computer vision a public act. Datasets for face recognition are generally produced without consent using images across the web, computer vision is increasingly common in public infrastructures, and decisions made with computer vision already influence policy and acts of policing, such as racial profiling and forensic surveillance. 

Taken together, I hope these approaches may especially educate people with privilege, such as myself, about how they perpetuate algocracy, benefit from it, and may resist and change it through practices invested in just conditions. Otherwise, we risk delegating responsibility for questions of justice to the rule of code. 
